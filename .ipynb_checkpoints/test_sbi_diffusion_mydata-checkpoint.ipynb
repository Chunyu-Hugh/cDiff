{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1d683a85de1494",
   "metadata": {},
   "source": [
    "# Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6153f4fdaf8403a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T21:16:45.436192Z",
     "start_time": "2025-10-27T21:16:45.400921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 cDiff 项目: /home/chu034/Yaohang_Li/cDiff\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 搜索 cDiff 目录\n",
    "home = Path.home()\n",
    "for item in home.iterdir():\n",
    "    if item.is_dir() and item.name == 'cDiff':\n",
    "        print(f\"找到 cDiff 项目: {item}\")\n",
    "    if item.is_dir() and (item / 'cDiff').exists():\n",
    "        print(f\"找到 cDiff 项目: {item / 'cDiff'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T21:17:00.292732Z",
     "start_time": "2025-10-27T21:17:00.227092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "项目路径: /home/chu034/Yaohang_Li/cDiff\n",
      "Python 路径已更新\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from src.data import generate_data_batch, clamp_to_inference_bounds\n",
    "# SBI imports\n",
    "# from sbi import utils as utils\n",
    "# from sbi.inference import NPE, SNPE\n",
    "# from sbi.utils import BoxUniform, MultipleIndependent\n",
    "\n",
    "# Local imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Ensure project root is on sys.path so we can import the src package\n",
    "# Local imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 设置项目根目录（请根据实际情况修改这个路径）\n",
    "project_root = Path('/home/chu034/Yaohang_Li/cDiff')  # 修改为你的实际路径\n",
    "\n",
    "# 验证路径是否正确\n",
    "if not project_root.exists():\n",
    "    raise FileNotFoundError(f\"找不到项目目录: {project_root}\")\n",
    "\n",
    "if not (project_root / 'src').exists():\n",
    "    raise FileNotFoundError(f\"项目目录下找不到 src 文件夹: {project_root / 'src'}\")\n",
    "\n",
    "# 添加到系统路径\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"项目路径: {project_root}\")\n",
    "print(f\"Python 路径已更新\")\n",
    "\n",
    "from src.data import generate_data_batch, clamp_to_inference_bounds\n",
    "\n",
    "from src.physics import (\n",
    "    pmin, pmax, amin, amax, bmin, bmax, qmin, qmax, cmin, cmax, dmin, dmax,\n",
    "    pmin_r, pmax_r, amin_r, amax_r, bmin_r, bmax_r, qmin_r, qmax_r, cmin_r, cmax_r, dmin_r, dmax_r,\n",
    "    get_sigma1, get_sigma2, gen_events\n",
    ")\n",
    "from src.metrics import histogram_kl, norm_mse\n",
    "from src.viz import plot_parameter_comparison\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348389a5099276c1",
   "metadata": {},
   "source": [
    "# define the simulator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b084e7e4f09612c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing simulator...\n",
      "Generated data sh ape: torch.Size([1, 10000, 2])\n",
      "Generated norm shape: torch.Size([1, 2])\n",
      "Sample events (first 5): tensor([[0.4525, 0.5543],\n",
      "        [0.1175, 0.5892],\n",
      "        [0.2139, 0.7364],\n",
      "        [0.2895, 0.3688],\n",
      "        [0.6792, 0.4699]])\n",
      "Sample norms: tensor([2.0842, 1.2190])\n"
     ]
    }
   ],
   "source": [
    "def physics_simulator(theta, num_points=1000):\n",
    "    \"\"\"\n",
    "    Simulator function for SBI.\n",
    "\n",
    "    Args:\n",
    "        theta: Parameter tensor of shape (batch_size, 6) containing [p, a, b, q, c, d]\n",
    "        num_points: Number of events to generate per simulation\n",
    "\n",
    "    Returns:\n",
    "        x: Event data tensor of shape (batch_size, num_points, 2)\n",
    "        norm: Normalization constants tensor of shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    # Convert to numpy for compatibility with existing functions\n",
    "    if isinstance(theta, torch.Tensor):\n",
    "        theta_np = theta.detach().cpu().numpy()\n",
    "    else:\n",
    "        theta_np = theta\n",
    "\n",
    "    batch_size = theta_np.shape[0]\n",
    "    x_list, norm_list = [], []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Generate events for sigma1 and sigma2\n",
    "        s1_events, s1_norm, _ = gen_events(lambda x: get_sigma1(x, theta_np[i]), nevents=num_points)\n",
    "        s2_events, s2_norm, _ = gen_events(lambda x: get_sigma2(x, theta_np[i]), nevents=num_points)\n",
    "\n",
    "        # Stack events and norms\n",
    "        events = np.stack([s1_events, s2_events], axis=1)\n",
    "        x_list.append(events)\n",
    "        norm_list.append([s1_norm, s2_norm])\n",
    "\n",
    "    # Convert back to tensors\n",
    "    x = torch.from_numpy(np.stack(x_list)).float()\n",
    "    norm = torch.from_numpy(np.stack(norm_list)).float()\n",
    "\n",
    "    return x, norm\n",
    "\n",
    "# Test the simulator just for test\n",
    "print(\"Testing simulator...\")\n",
    "test_params = torch.tensor([[0.5, -0.5, 0.5, 0.5, 0.5, 0.5]])\n",
    "test_x, test_norm = physics_simulator(test_params, num_points=10000)\n",
    "print(f\"Generated data sh ape: {test_x.shape}\")\n",
    "print(f\"Generated norm shape: {test_norm.shape}\")\n",
    "print(f\"Sample events (first 5): {test_x[0, :5, :]}\")\n",
    "print(f\"Sample norms: {test_norm[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9a20037e5feb3",
   "metadata": {},
   "source": [
    "# define prior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637e070665f9499b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BoxUniform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m prior_upper = torch.tensor([pmax_r, amax_r, bmax_r, qmax_r, cmax_r, dmax_r])\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Create uniform prior\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m prior = \u001b[43mBoxUniform\u001b[49m(low=prior_lower, high=prior_upper,device=device)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrior distributions:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m param_names = [\u001b[33m'\u001b[39m\u001b[33mp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'BoxUniform' is not defined"
     ]
    }
   ],
   "source": [
    "pmin_r, pmax_r = 0.0, 1.0\n",
    "amin_r , amax_r = -1.0, 0.0\n",
    "bmin_r, bmax_r = 0.0, 1.0\n",
    "qmin_r, qmax_r = 0.0, 1.0\n",
    "cmin_r, cmax_r = 0.0, 1.0\n",
    "dmin_r, dmax_r = 0.0, 1.0\n",
    "# Define prior distributions for the 6 parameters\n",
    "# Using the broader inference ranges for the prior\n",
    "prior_lower = torch.tensor([pmin_r, amin_r, bmin_r, qmin_r, cmin_r, dmin_r])\n",
    "prior_upper = torch.tensor([pmax_r, amax_r, bmax_r, qmax_r, cmax_r, dmax_r])\n",
    "\n",
    "# Create uniform prior\n",
    "prior = BoxUniform(low=prior_lower, high=prior_upper,device=device)\n",
    "\n",
    "print(\"Prior distributions:\")\n",
    "param_names = ['p', 'a', 'b', 'q', 'c', 'd']\n",
    "for i, name in enumerate(param_names):\n",
    "    print(f\"{name}: [{prior_lower[i]:.1f}, {prior_upper[i]:.1f}]\")\n",
    "\n",
    "# Sample from prior to test\n",
    "prior_samples = prior.sample((5,))\n",
    "print(f\"\\nPrior samples shape: {prior_samples.shape}\")\n",
    "print(f\"Sample parameters: {prior_samples[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ea8c67b302f12",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e9761143df2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 智能数据管理 ==========\n",
    "import torch\n",
    "import os\n",
    "\n",
    "save_dir = './training_data'\n",
    "data_path = os.path.join(save_dir, 'training_data_10000_1000.pt')\n",
    "\n",
    "# 检查数据文件是否存在\n",
    "if os.path.exists(data_path):\n",
    "    print(\"✓ 发现已存在的训练数据文件，正在加载...\")\n",
    "    data = torch.load(data_path)\n",
    "\n",
    "    theta_train = data['theta_train']\n",
    "    x_train = data['x_train']\n",
    "    norm_train = data['norm_train']\n",
    "    num_simulations = data['num_simulations']\n",
    "    num_points_per_sim = data['num_points_per_sim']\n",
    "    param_names = data['param_names']\n",
    "\n",
    "    print(f\"✓ 训练数据加载成功！\")\n",
    "    print(f\"Parameters: {theta_train.shape}\")\n",
    "    print(f\"Events: {x_train.shape}\")\n",
    "    print(f\"Norms: {norm_train.shape}\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠ 未发现训练数据文件，正在生成新数据...\")\n",
    "    num_simulations = 10000\n",
    "    num_points_per_sim = 1000\n",
    "\n",
    "    # Sample parameters from prior\n",
    "    theta_train = prior.sample((num_simulations,))\n",
    "\n",
    "    # Generate simulations\n",
    "    x_train, norm_train = physics_simulator(theta_train, num_points_per_sim)\n",
    "\n",
    "    print(f\"✓ 训练数据生成完成！\")\n",
    "    print(f\"Parameters: {theta_train.shape}\")\n",
    "    print(f\"Events: {x_train.shape}\")\n",
    "    print(f\"Norms: {norm_train.shape}\")\n",
    "\n",
    "    # 保存新生成的数据\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    torch.save({\n",
    "        'theta_train': theta_train,\n",
    "        'x_train': x_train,\n",
    "        'norm_train': norm_train,\n",
    "        'num_simulations': num_simulations,\n",
    "        'num_points_per_sim': num_points_per_sim,\n",
    "        'param_names': param_names\n",
    "    }, data_path)\n",
    "    print(f\"✓ 训练数据已保存到 {data_path}\")\n",
    "\n",
    "# ========== 数据可视化 ==========\n",
    "print(\"\\n正在展示训练数据...\")\n",
    "\n",
    "# Visualize parameter distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(6):\n",
    "    axes[i].hist(theta_train[:, i].cpu().numpy(), bins=50, alpha=0.7, density=True)\n",
    "    axes[i].set_title(f'Parameter {param_names[i]} Distribution')\n",
    "    axes[i].set_xlabel('Value')\n",
    "    axes[i].set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show some example event distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot sigma1 events\n",
    "axes[0].hist(x_train[0, :, 0].numpy(), bins=50, alpha=0.7, density=True)\n",
    "axes[0].set_title('Sigma1 Events Distribution (Sample)')\n",
    "axes[0].set_xlabel('Event Value')\n",
    "axes[0].set_ylabel('Density')\n",
    "\n",
    "# Plot sigma2 events\n",
    "axes[1].hist(x_train[0, :, 1].numpy(), bins=50, alpha=0.7, density=True)\n",
    "axes[1].set_title('Sigma2 Events Distribution (Sample)')\n",
    "axes[1].set_xlabel('Event Value')\n",
    "axes[1].set_ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ 数据展示完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10964767ad0f35af",
   "metadata": {},
   "source": [
    "# change originial data to my task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5475f9aae439d78b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T20:58:35.641543Z",
     "start_time": "2025-10-27T20:58:31.544476Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2579914/1189479064.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Cell: 训练 Diffusion Model\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657320035331fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========== 训练参数配置 ==========\n",
    "# 数据集参数\n",
    "N_BATCHES = 2\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 模型参数\n",
    "N_SUMMARIES = 256\n",
    "USE_ENCODER = False  # 因为我们的数据不需要 encoder\n",
    "DATA_TYPE = \"iid\"\n",
    "SIGMA_DATA = 0.5\n",
    "NUM_HIDDEN_LAYER = 4\n",
    "\n",
    "# 训练参数\n",
    "EPOCHS = 500  # 可以根据需要调整\n",
    "LR = 1e-3\n",
    "LR_DECAY = True\n",
    "EVAL_INTERVAL = 40\n",
    "SAVE_MODEL_FLAG = True\n",
    "\n",
    "# 评估参数\n",
    "N_CAL = 1000\n",
    "L = 100\n",
    "SEED = 1\n",
    "MODEL_TYPE = \"Diffusion\"\n",
    "\n",
    "# 路径\n",
    "SAVE_PATH = \"./result/mydata\"\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"训练参数配置:\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Learning Rate: {LR}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Save Path: {SAVE_PATH}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========== 设置随机种子 ==========\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# ========== 准备数据 ==========\n",
    "# 使用前面生成的数据: theta_train (10000, 6), x_train (10000, 1000, 2)\n",
    "# 需要将 x_train 转换为适合模型的格式\n",
    "\n",
    "# 对于这个任务,我们需要将 x_train reshape 成 (10000, 2000)\n",
    "# 即把两个 sigma 的事件合并\n",
    "y_train = x_train.reshape(x_train.shape[0], -1)  # (10000, 2000)\n",
    "\n",
    "print(f\"\\n数据形状:\")\n",
    "print(f\"Parameters (theta): {theta_train.shape}\")\n",
    "print(f\"Observations (y): {y_train.shape}\")\n",
    "\n",
    "y_dim = y_train.shape[-1]  # 2000\n",
    "theta_dim = theta_train.shape[1]  # 6\n",
    "\n",
    "# 创建 DataLoader\n",
    "dataset = TensorDataset(theta_train, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ========== 初始化模型 ==========\n",
    "from models.neural_sampler import DiffusionPosteriorSampler\n",
    "\n",
    "model = DiffusionPosteriorSampler(\n",
    "    y_dim=y_dim,\n",
    "    x_dim=theta_dim,\n",
    "    n_summaries=N_SUMMARIES,\n",
    "    num_hidden_layer=NUM_HIDDEN_LAYER,\n",
    "    device=device,\n",
    "    use_encoder=USE_ENCODER,\n",
    "    data_type=DATA_TYPE,\n",
    "    sigma_data=SIGMA_DATA\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\n模型初始化完成!\")\n",
    "print(f\"模型参数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ========== 初始化优化器 ==========\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# ========== 训练循环 ==========\n",
    "loss_record = []\n",
    "training_time_record = []\n",
    "\n",
    "print(f\"\\n开始训练 {EPOCHS} 个 epochs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training\"):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "\n",
    "    for batch_idx, (theta, y) in enumerate(data_loader):\n",
    "        # 数据移到设备\n",
    "        theta = theta.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(x=theta, y=y).mean()\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=100.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(float(loss))\n",
    "\n",
    "    # 学习率调整\n",
    "    if LR_DECAY:\n",
    "        scheduler.step()\n",
    "\n",
    "    # 记录\n",
    "    avg_loss = np.mean(epoch_loss)\n",
    "    epoch_time = time.time() - start_time\n",
    "    loss_record.append(avg_loss)\n",
    "    training_time_record.append(epoch_time)\n",
    "\n",
    "    # 打印进度\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        lr = scheduler.get_last_lr()[0] if LR_DECAY else LR\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.4f} | \"\n",
    "              f\"LR: {lr:.6f} | Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # 定期保存模型\n",
    "    if SAVE_MODEL_FLAG and (epoch + 1) % EVAL_INTERVAL == 0:\n",
    "        model_path = f\"{SAVE_PATH}/{epoch+1}_seed={SEED}_{MODEL_TYPE}.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        if (epoch + 1) % (EVAL_INTERVAL * 5) == 0:  # 每5个间隔打印一次\n",
    "            print(f\"模型已保存到: {model_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"训练完成!\")\n",
    "\n",
    "# ========== 保存训练记录 ==========\n",
    "df_loss = pd.DataFrame({\n",
    "    'epochs': list(range(1, len(loss_record) + 1)),\n",
    "    'loss': loss_record,\n",
    "    'seed': SEED,\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'training_time': training_time_record\n",
    "})\n",
    "\n",
    "loss_save_path = f\"{SAVE_PATH}/loss.csv\"\n",
    "df_loss.to_csv(loss_save_path, index=False)\n",
    "print(f\"\\n训练记录已保存到: {loss_save_path}\")\n",
    "\n",
    "# 训练统计\n",
    "print(f\"\\n训练统计:\")\n",
    "print(f\"总时间: {sum(training_time_record):.2f}s\")\n",
    "print(f\"平均每轮: {np.mean(training_time_record):.2f}s\")\n",
    "print(f\"最终 loss: {loss_record[-1]:.4f}\")\n",
    "print(f\"最小 loss: {min(loss_record):.4f} (Epoch {loss_record.index(min(loss_record)) + 1})\")\n",
    "\n",
    "# ========== 绘制训练曲线 ==========\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss 曲线\n",
    "axes[0].plot(df_loss['epochs'], df_loss['loss'], linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training Loss Curve', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=min(loss_record), color='r', linestyle='--', alpha=0.5, label=f'Min Loss: {min(loss_record):.4f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# 学习率曲线\n",
    "if LR_DECAY:\n",
    "    lrs = [LR * (1e-6/LR + (1 - 1e-6/LR) * (1 + np.cos(np.pi * e / EPOCHS)) / 2)\n",
    "           for e in range(EPOCHS)]\n",
    "    axes[1].plot(range(1, EPOCHS+1), lrs, linewidth=2, color='orange')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[1].set_title('Learning Rate Schedule', fontsize=14)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_yscale('log')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'No LR Decay', ha='center', va='center', fontsize=16)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{SAVE_PATH}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n训练曲线已保存到: {SAVE_PATH}/training_curves.png\")\n",
    "\n",
    "# ========== 保存最终模型 ==========\n",
    "if SAVE_MODEL_FLAG:\n",
    "    final_model_path = f\"{SAVE_PATH}/{EPOCHS}_seed={SEED}_{MODEL_TYPE}_final.pth\"\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"最终模型已保存到: {final_model_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"所有训练流程完成!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
