{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f814e732",
   "metadata": {},
   "source": [
    "# Circle Dataset with Diffusion Model\n",
    "\n",
    "本 notebook 演示如何使用 Diffusion 模型学习圆的数据生成：给定半径 z，生成 (x,y) 坐标点。\n",
    "\n",
    "## 数据集说明\n",
    "- **circle.py**: z ~ Uniform[0, 2] (半径)\n",
    "- **数据生成**: x = z cos(t), y = z sin(t), t ~ Uniform[0, 2π]\n",
    "- **噪声**: 可选的 Gaussian 噪声 (NOISE_SIGMA)\n",
    "- **任务**: 学习 p(y=(x,y) | z), 即给定 z 生成 y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ffa8fd",
   "metadata": {},
   "source": [
    "## 1. 项目路径设置\n",
    "\n",
    "设置 Python 路径以正确导入模块。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f11b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "项目路径: /home/chu034/Yaohang_Li/cDiff\n",
      "Python 路径已更新\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "# Project path setup\n",
    "project_root = Path.cwd()\n",
    "if (project_root / 'src').exists():\n",
    "    pass\n",
    "else:\n",
    "    # Fallback: user-specific path\n",
    "    project_root = Path('/home/chu034/Yaohang_Li/cDiff')\n",
    "\n",
    "\n",
    "if not project_root.exists() or not (project_root / 'src').exists():\n",
    "    raise FileNotFoundError(f\"找不到项目目录或 src: {project_root}\")\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"项目路径: {project_root}\")\n",
    "print(\"Python 路径已更新\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0002f1",
   "metadata": {},
   "source": [
    "## 2. 导入依赖\n",
    "\n",
    "导入所需的库和模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864c08e",
   "metadata": {},
   "source": [
    "## 3. 配置参数\n",
    "\n",
    "设置数据集、模型和训练的超参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba287c",
   "metadata": {},
   "source": [
    "## 4. 加载 circle 数据集\n",
    "\n",
    "使用 circle 数据集生成器，设置可选的 (x,y) 噪声。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7257e3",
   "metadata": {},
   "source": [
    "## 5. 初始化模型\n",
    "\n",
    "**注意**: 这里模型学习的是 p(y=(x,y) | z)，即给定半径 z 生成 (x,y) 坐标。\n",
    "- `x_dim = 2`: 生成维度（生成 (x,y)）\n",
    "- `y_dim_cond = 1`: 条件维度（条件 z）\n",
    "- `loss(x=y, y=theta)`: 训练时用 y 作为目标，theta(z) 作为条件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ed534",
   "metadata": {},
   "source": [
    "## 6. 训练循环\n",
    "\n",
    "训练模型学习 p(y|z) 分布。每个 epoch 结束后重置 batch sample sizes。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e5705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2601572/259258266.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Notebook-ready minimal training for circle dataset\n",
    "# CHANGED: converted script to runnable notebook; dataset set to circle\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from models.neural_sampler import NormalizingFlowPosteriorSampler, DiffusionPosteriorSampler\n",
    "from utils import *\n",
    "\n",
    "# ===== Config (edit here) =====\n",
    "DATASET = \"circle\"  # CHANGED: use circle dataset\n",
    "MODEL = \"Diffusion\"  # \"NormalizingFlow\" or \"Diffusion\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHS = 1000\n",
    "N_BATCHES = 20\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "LR_DECAY = False\n",
    "ALPHA = 0.1\n",
    "USE_ENCODER = True\n",
    "NUM_HIDDEN_LAYER = 4\n",
    "SAVE_DIR = \"./test\"\n",
    "\n",
    "# CHANGED: set Gaussian noise on (x, y)\n",
    "from datasets.circle import set_circle_noise_sigma\n",
    "NOISE_SIGMA = 0.05  # std of noise added to (x,y)\n",
    "set_circle_noise_sigma(NOISE_SIGMA)\n",
    "\n",
    "# ===== Load circle dataset =====\n",
    "# CHANGED: load circle via registry instead of CLI args\n",
    "dataset_generator, sample_theta, sample_data = load_dataset(DATASET)\n",
    "if USE_ENCODER:\n",
    "    dl = dataset_generator(N_BATCHES, BATCH_SIZE, return_ds=False)\n",
    "else:\n",
    "    dl = dataset_generator(N_BATCHES, BATCH_SIZE, n_sample=1, return_ds=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e25c3",
   "metadata": {},
   "source": [
    "## 7. 测试：给定 z=2 生成 (x,y) 坐标\n",
    "\n",
    "使用训练好的模型，给定 z=2 生成 500 个 (x,y) 坐标点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd8bbd",
   "metadata": {},
   "source": [
    "## 8. 可视化生成的圆\n",
    "\n",
    "- **红虚线**: 理想圆 r=2\n",
    "- **散点**: 模型生成的 (x,y) 坐标 | z=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5c45f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder is for iid data. If not, please check it.\n"
     ]
    }
   ],
   "source": [
    "theta, y = next(iter(dl))\n",
    "y_dim = y.shape[-1]          # 2 (x,y)\n",
    "theta_dim = theta.shape[1]   # 1 (z)\n",
    "\n",
    "# learn p(y | z): condition=z (1), generate y=(x,y) (2)\n",
    "x_dim = y_dim               # generate (x,y)\n",
    "y_dim_cond = theta_dim      # condition z\n",
    "\n",
    "if MODEL == \"NormalizingFlow\":\n",
    "    model = NormalizingFlowPosteriorSampler(\n",
    "        y_dim=y_dim_cond,\n",
    "        x_dim=x_dim,\n",
    "        n_summaries=256,\n",
    "        hidden_dim_decoder=32,\n",
    "        n_flows_decoder=32,\n",
    "        alpha=ALPHA,\n",
    "        device=DEVICE,\n",
    "        use_encoder=USE_ENCODER,\n",
    "        data_type=\"iid\",\n",
    "    ).to(DEVICE)\n",
    "elif MODEL == \"Diffusion\":\n",
    "    sigma_data = 0.5\n",
    "    model = DiffusionPosteriorSampler(\n",
    "        y_dim=y_dim_cond,\n",
    "        x_dim=x_dim,\n",
    "        n_summaries=256,\n",
    "        num_hidden_layer=NUM_HIDDEN_LAYER,\n",
    "        device=DEVICE,\n",
    "        use_encoder=USE_ENCODER,\n",
    "        data_type=\"iid\",\n",
    "        sigma_data=sigma_data,\n",
    "    ).to(DEVICE)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# ===== Optimizer/Scheduler =====\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# ===== Recreate DL with dataset object for reset =====\n",
    "# CHANGED: request ds so we can call reset_batch_sample_sizes per epoch\n",
    "dl, ds = dataset_generator(N_BATCHES, BATCH_SIZE, None if USE_ENCODER else 1, return_ds=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4c0e41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m theta = theta.to(DEVICE)\n\u001b[32m     15\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m loss = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m.mean()\n\u001b[32m     17\u001b[39m epoch_loss.append(\u001b[38;5;28mfloat\u001b[39m(loss))\n\u001b[32m     18\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Yaohang_Li/cDiff/models/neural_sampler.py:127\u001b[39m, in \u001b[36mDiffusionPosteriorSampler.loss\u001b[39m\u001b[34m(self, x, y)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_encoder \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# diffusion_loss = self.diffusion.diffusion_loss(self.decoder, x, s).mean()\u001b[39;00m\n\u001b[32m    129\u001b[39m     diffusion_loss = \u001b[38;5;28mself\u001b[39m.diffusion.diffusion_train_step(\u001b[38;5;28mself\u001b[39m.decoder, x, s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cdiff/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cdiff/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Yaohang_Li/cDiff/models/summary.py:49\u001b[39m, in \u001b[36mDeepSetSummary.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     batch_size, n_samples, n_features = x.shape\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# Apply z-score normalization\u001b[39;00m\n\u001b[32m     52\u001b[39m     normalized_x, (mean, std_dev) = zscore(x, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Training Loop =====\n",
    "loss_record = []\n",
    "training_time_record = []\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    epoch_loss = []\n",
    "\n",
    "    for batch in dl:\n",
    "        theta, y = batch\n",
    "        if y.shape[1] == 1:\n",
    "            y = y.squeeze(1)\n",
    "        y = y.to(DEVICE)\n",
    "        theta = theta.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(x=y, y=theta).mean()\n",
    "        epoch_loss.append(float(loss))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=100.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    if LR_DECAY:\n",
    "        scheduler.step()\n",
    "\n",
    "    # CHANGED: reset sample sizes per epoch for streaming circle data\n",
    "    ds.reset_batch_sample_sizes()\n",
    "    if epoch%10==0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}  Loss {np.mean(epoch_loss):.4f}  LR {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    loss_record.append(np.mean(epoch_loss))\n",
    "    training_time_record.append(time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "with torch.no_grad():\n",
    "    N = 500\n",
    "    z_cond = torch.full((N, 1), 2.0, device=DEVICE)  # 只输入 z=2\n",
    "    y_gen = model.sample(z_cond, num_steps=18).cpu().numpy()  # (N, 2)\n",
    "\n",
    "print(\"y_gen shape:\", y_gen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf315693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(y_gen[:,0], y_gen[:,1], s=8, alpha=0.6, label='generated y|z=2')\n",
    "tt = np.linspace(0, 2*np.pi, 400)\n",
    "plt.plot(2*np.cos(tt), 2*np.sin(tt), 'r--', label='ideal circle r=2')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.legend(); plt.grid(True, alpha=0.3); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
