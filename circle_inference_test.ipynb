{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Circle dataset — Diffusion model inference (trained model)\n",
        "\n",
        "This notebook loads a pre-trained Diffusion posterior sampler and performs inference on the circle dataset. Configure `load_path`, `epochs`, and `seed` to match your saved checkpoint names.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "项目路径: /home/chu034/Yaohang_Li/cDiff\n",
            "Python 路径已更新\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "# Project path setup\n",
        "project_root = Path.cwd()\n",
        "if (project_root / 'src').exists():\n",
        "    pass\n",
        "else:\n",
        "    # Fallback: user-specific path\n",
        "    project_root = Path('/home/chu034/Yaohang_Li/cDiff')\n",
        "\n",
        "\n",
        "if not project_root.exists() or not (project_root / 'src').exists():\n",
        "    raise FileNotFoundError(f\"找不到项目目录或 src: {project_root}\")\n",
        "\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"项目路径: {project_root}\")\n",
        "print(\"Python 路径已更新\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets.circle import return_circle_dl, set_circle_noise_sigma\n",
        "from models.neural_sampler import DiffusionPosteriorSampler\n",
        "from utils import load_torch_model, SET_SEED\n",
        "\n",
        "# ----- Config -----\n",
        "# Match these with your training run\n",
        "load_path = \"/home/chu034/Yaohang_Li/cDiff/result/circle\"   # --save_path result --dataset circle\n",
        "epochs = 4160                  # --epochs 5000\n",
        "seed = 1                       # pick a trained seed in [1..10] per your run\n",
        "model_type = \"Diffusion\"       # --model Diffusion (nickname if any was appended during training)\n",
        "\n",
        "# Device config\n",
        "cuda_index = 0                 # --device 0\n",
        "DEVICE = torch.device(f\"cuda:{cuda_index}\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data config\n",
        "n_batches = 2\n",
        "batch_size = 512\n",
        "n_sample = None  # encoder ON in training; dataset returns variable set sizes\n",
        "noise_sigma = 0.0  # optional: add noise to observed radius values\n",
        "\n",
        "# Reproducibility for sampling/plotting\n",
        "SET_SEED(42)\n",
        "\n",
        "# Optional: set noise level used to generate observed radii (y)\n",
        "set_circle_noise_sigma(noise_sigma)\n",
        "print(f\"Using device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "theta_true shape: torch.Size([512, 2])\n",
            "y_obs shape: torch.Size([512, 960, 1])\n",
            "y_dim=1, x_dim=2\n"
          ]
        }
      ],
      "source": [
        "# Build a small dataloader and fetch one batch\n",
        "\n",
        "dl, ds = return_circle_dl(n_batches=n_batches, batch_size=batch_size, n_sample=n_sample, return_ds=True)\n",
        "\n",
        "theta_true, y_obs = next(iter(dl))  # theta_true: [B, 2], y_obs: [B, set_size, 1]\n",
        "print(\"theta_true shape:\", theta_true.shape)\n",
        "print(\"y_obs shape:\", y_obs.shape)\n",
        "\n",
        "y_dim = y_obs.shape[-1]\n",
        "x_dim = theta_true.shape[1]\n",
        "print(f\"y_dim={y_dim}, x_dim={x_dim}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder is for iid data. If not, please check it.\n",
            "Model loaded from /home/chu034/Yaohang_Li/cDiff/result/circle/4160_seed=1_Diffusion.pth\n",
            "Model loaded and ready.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/chu034/Yaohang_Li/cDiff/utils.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(file_name))\n"
          ]
        }
      ],
      "source": [
        "# Reconstruct model architecture; must match training config\n",
        "n_summaries = 256          # from main.py\n",
        "num_hidden_layer = 4       # default training arg\n",
        "use_encoder = True         # you trained with --use_encoder\n",
        "sigma_data = 0.5           # you likely used default (unless --use_emperical_sigma was set)\n",
        "\n",
        "model = DiffusionPosteriorSampler(\n",
        "    y_dim=y_dim,\n",
        "    x_dim=x_dim,\n",
        "    n_summaries=n_summaries,\n",
        "    num_hidden_layer=num_hidden_layer,\n",
        "    device=DEVICE,\n",
        "    use_encoder=use_encoder,\n",
        "    data_type=\"iid\",\n",
        "    sigma_data=sigma_data,\n",
        ").to(DEVICE)\n",
        "\n",
        "# Load weights — filenames are: {load_path}/{epochs}_seed={seed}_{model_type}.pth\n",
        "model = load_torch_model(model, load_path, epochs, seed, model_type)\n",
        "_ = model.to(DEVICE).eval()\n",
        "\n",
        "print(\"Model loaded and ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference: posterior samples of theta given observed y\n",
        "\n",
        "y_batch = y_obs.to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    theta_est = model.sample(y_batch, num_steps=18)  # [B, 2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[nan, nan],\n",
              "        [nan, nan],\n",
              "        [nan, nan],\n",
              "        ...,\n",
              "        [nan, nan],\n",
              "        [nan, nan],\n",
              "        [nan, nan]], device='cuda:0')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "theta_est"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "theta_est_cpu = theta_est.detach().cpu().numpy()\n",
        "theta_true_cpu = theta_true.detach().cpu().numpy()\n",
        "\n",
        "# Scatter: true theta vs estimated theta per dim\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(x_dim):\n",
        "    plt.subplot(1, x_dim, i + 1)\n",
        "    plt.scatter(theta_true_cpu[:, i], theta_est_cpu[:, i], s=10, alpha=0.5)\n",
        "    plt.xlabel(f\"True theta[{i}]\")\n",
        "    plt.ylabel(f\"Est theta[{i}]\")\n",
        "    plt.title(f\"Dim {i}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: visualize samples for one observed set y\n",
        "idx = 0\n",
        "one_y = y_batch[idx:idx+1]\n",
        "with torch.no_grad():\n",
        "    samples = model.sample(one_y, num_steps=18)  # [1, 2]\n",
        "\n",
        "# For visualization, draw multiple samples by repeating the same condition\n",
        "with torch.no_grad():\n",
        "    cond = one_y.repeat(200, 1, 1)  # 200 posterior samples\n",
        "    samples_many = model.sample(cond, num_steps=18).detach().cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(samples_many[:, 0], samples_many[:, 1], s=10, alpha=0.6)\n",
        "plt.xlabel(\"theta[0]\")\n",
        "plt.ylabel(\"theta[1]\")\n",
        "plt.title(\"Posterior samples for one observed set y\")\n",
        "plt.axis('equal')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
